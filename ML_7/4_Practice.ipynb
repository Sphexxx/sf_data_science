{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zTpqv-tvlZ5"
      },
      "source": [
        "## Необходимо предсказать биологический ответ молекул (столбец 'Activity') по их химическому составу (столбцы D1-D1776)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGrxZiwkvlZ9",
        "outputId": "70b48886-d45b-48b8-db01-1343443ab559"
      },
      "outputs": [],
      "source": [
        "#импорт библиотек\n",
        "import numpy as np #для матричных вычислений\n",
        "import pandas as pd #для анализа и предобработки данных\n",
        "import matplotlib.pyplot as plt #для визуализации\n",
        "import seaborn as sns #для визуализации\n",
        "\n",
        "from sklearn import linear_model #линейные модели\n",
        "from sklearn import tree #деревья решений\n",
        "from sklearn import ensemble #ансамбли\n",
        "from sklearn import metrics #метрики\n",
        "from sklearn import preprocessing #предобработка\n",
        "from sklearn.model_selection import train_test_split #сплитование выборки\n",
        "from sklearn.model_selection import cross_val_score #Кросс валидация\n",
        "\n",
        "# Импорт оптимизаторов параметров\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "import hyperopt\n",
        "from hyperopt import hp, fmin, tpe, Trials\n",
        "\n",
        "import optuna\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "llBfqp5cvlZ_",
        "outputId": "1505531b-f376-47f7-877b-d58e148c94b0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Activity</th>\n",
              "      <th>D1</th>\n",
              "      <th>D2</th>\n",
              "      <th>D3</th>\n",
              "      <th>D4</th>\n",
              "      <th>D5</th>\n",
              "      <th>D6</th>\n",
              "      <th>D7</th>\n",
              "      <th>D8</th>\n",
              "      <th>D9</th>\n",
              "      <th>...</th>\n",
              "      <th>D1767</th>\n",
              "      <th>D1768</th>\n",
              "      <th>D1769</th>\n",
              "      <th>D1770</th>\n",
              "      <th>D1771</th>\n",
              "      <th>D1772</th>\n",
              "      <th>D1773</th>\n",
              "      <th>D1774</th>\n",
              "      <th>D1775</th>\n",
              "      <th>D1776</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.497009</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.132956</td>\n",
              "      <td>0.678031</td>\n",
              "      <td>0.273166</td>\n",
              "      <td>0.585445</td>\n",
              "      <td>0.743663</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.606291</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111209</td>\n",
              "      <td>0.803455</td>\n",
              "      <td>0.106105</td>\n",
              "      <td>0.411754</td>\n",
              "      <td>0.836582</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.033300</td>\n",
              "      <td>0.480124</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.209791</td>\n",
              "      <td>0.610350</td>\n",
              "      <td>0.356453</td>\n",
              "      <td>0.517720</td>\n",
              "      <td>0.679051</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.538825</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.196344</td>\n",
              "      <td>0.724230</td>\n",
              "      <td>0.235606</td>\n",
              "      <td>0.288764</td>\n",
              "      <td>0.805110</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.517794</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.494734</td>\n",
              "      <td>0.781422</td>\n",
              "      <td>0.154361</td>\n",
              "      <td>0.303809</td>\n",
              "      <td>0.812646</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1777 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
              "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
              "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
              "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
              "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
              "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
              "\n",
              "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
              "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
              "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
              "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
              "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
              "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
              "\n",
              "   D1774  D1775  D1776  \n",
              "0      0      0      0  \n",
              "1      0      1      0  \n",
              "2      0      0      0  \n",
              "3      0      0      0  \n",
              "4      0      0      0  \n",
              "\n",
              "[5 rows x 1777 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('data/train_sem09.zip')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwz4uUDTvlaB"
      },
      "source": [
        "+ Первый столбец *Activity* содержит экспериментальные данные, описывающие фактический биологический ответ [0, 1]; \n",
        "+ Остальные столбцы D1-D1776 представляют собой молекулярные **дескрипторы** — это вычисляемые свойства, которые могут фиксировать некоторые характеристики молекулы, например размер, форму или состав элементов.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR0R-0iQvlaC"
      },
      "source": [
        "## Предварительная обработка не требуется, данные уже закодированы и нормализованы.\n",
        "\n",
        "В качестве метрики будем использовать **F1-score**.\n",
        "\n",
        "Необходимо обучить две модели: **логистическую регрессию и случайный лес**. Далее нужно сделать подбор гиперпараметров с помощью базовых и продвинутых методов оптимизации. Важно использовать **все четыре метода** (*GridSeachCV, RandomizedSearchCV, Hyperopt, Optuna*) хотя бы по разу, максимальное количество итераций не должно превышать 50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C7N0hj4uvlaC"
      },
      "outputs": [],
      "source": [
        "X = data.drop(['Activity'], axis = 1)\n",
        "y = data['Activity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kT5uS9TvlaD",
        "outputId": "692b492e-3913-4b92-9e15-b6c20d1b8369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер data (3751, 1777)\n",
            "Размер X (3751, 1776)\n",
            "Размер y (3751,)\n"
          ]
        }
      ],
      "source": [
        "#Проверим по размерам выборок что разделение прошло успешно\n",
        "\n",
        "print('Размер data', data.shape)\n",
        "print('Размер X', X.shape)\n",
        "print('Размер y', y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqk5UAiwvlaD",
        "outputId": "d860ba65-f0ae-47cb-8044-f4fc81dbeedb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    0.542255\n",
              "0    0.457745\n",
              "Name: Activity, dtype: float64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Проверим, насколько равномерно разделены целевые данные\n",
        "y.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD6h-U-gvlaE"
      },
      "source": [
        "Данные разделены примерно одинаково, поэтому делать стратификацию не обязательно"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tRPSRu1uvlaF"
      },
      "outputs": [],
      "source": [
        "#Разделим данные на тренировочные и тестовые\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95SmNCgSvlaF"
      },
      "source": [
        "## **Создание BaseLine моделей**\n",
        "\n",
        "Рассчитаем F1-score, на параметрах по умолчанию, для моделей логистической регрессии и случайном леса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-XtC3oHvlaG",
        "outputId": "9a28b76f-60c4-44aa-aceb-c6625ced3d51"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "#Baseline для логистической регрессии\n",
        "logReg_base = linear_model.LogisticRegression(random_state=42, max_iter= 50)\n",
        "\n",
        "logReg_base.fit(X_train, y_train)\n",
        "\n",
        "y_pred_logReg_base = logReg_base.predict(X_test)\n",
        "\n",
        "f1_logReg_base = metrics.f1_score(y_test, y_pred_logReg_base)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa8vygUIvlaG",
        "outputId": "3f234eba-697a-4ded-8288-f07581ecd3d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для логистической регресии равен 0.79\n"
          ]
        }
      ],
      "source": [
        "print('F1-score на Baseline для логистической регресии равен {:.2f}'.format(f1_logReg_base))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eN7fWKirvlaH"
      },
      "outputs": [],
      "source": [
        "#Baseline для случайного леса\n",
        "\n",
        "rf_base = ensemble.RandomForestClassifier(random_state= 42)\n",
        "\n",
        "rf_base.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf_base = rf_base.predict(X_test)\n",
        "\n",
        "f1_rf_base = metrics.f1_score(y_test, y_pred_rf_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-fFigyYvlaH",
        "outputId": "cdd98ead-b347-4106-919d-63785ec4da2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для случайного леса равен 0.83\n"
          ]
        }
      ],
      "source": [
        "print('F1-score на Baseline для случайного леса равен {:.2f}'.format(f1_rf_base))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDjl3UkkwM2Z"
      },
      "source": [
        "## **Построение модели с помощью GridSearchCV**\n",
        "\n",
        "На основе логистической регресии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LAbI47ZvlaI",
        "outputId": "def0cd42-b347-4234-ba97-23e4444e01c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 18.5 s, sys: 2.31 s, total: 20.8 s\n",
            "Wall time: 25min 40s\n"
          ]
        }
      ],
      "source": [
        "param_grid = [\n",
        "    {'penalty' : ['l2', 'none'], # тип регуляризации\n",
        "    'solver' : ['newton-cg', 'lbfgs', 'sag'], # алгоритм оптимизации\n",
        "    'C' : [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}, # уровень силы регурялизации\n",
        "    \n",
        "    #поскольку разные алгоритмы поддерживают разные типы регуляризации мы создадим еще 1 набор параметров\n",
        "    {'penalty': ['l1', 'l2'] ,\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}\n",
        "]\n",
        "\n",
        "gs_logReg = GridSearchCV(\n",
        "    estimator = linear_model.LogisticRegression(random_state= 42, max_iter = 50),\n",
        "    param_grid = param_grid,\n",
        "    cv = 5,\n",
        "    n_jobs = -1,\n",
        "    scoring = 'f1'\n",
        ")\n",
        "\n",
        "%time gs_logReg.fit(X_train, y_train)\n",
        "\n",
        "y_pred_gs_logReg = gs_logReg.predict(X_test)\n",
        "\n",
        "f1_gs_logReg = metrics.f1_score(y_test, y_pred_gs_logReg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdCKftWA_ZOa",
        "outputId": "0ce51932-87b2-41fe-8a02-af1a2a7a6def"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наилучшие значения гиперпараметров: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
          ]
        }
      ],
      "source": [
        "print(\"Наилучшие значения гиперпараметров: {}\".format(gs_logReg.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "lC0iulFM_Zxr",
        "outputId": "4961b23e-bc96-4731-ab9a-8064dd71e349"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# посмотрим как менялась точность при различных гиперпараметрах\n",
        "visual = pd.pivot_table(pd.DataFrame(gs_logReg.cv_results_),\n",
        "                        values ='mean_test_score', index ='param_C',\n",
        "                        columns ='param_solver')\n",
        "sns.heatmap(visual)\n",
        "plt.title('Тепловая карта зависимости метрики accuracy от solver и С') # подпись графика\n",
        "sns.set(rc={'figure.figsize':(15, 8)}) #задаем размер графика"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-Yj-exg_mnu"
      },
      "source": [
        "Из тепловой карты видно, что нет смысла пробовать создать модель с большей силой регуляризации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18AeeChJ_iNd",
        "outputId": "f2d2745c-cf38-4377-9639-79a948bf28fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для логистической регресии равен 0.79\n",
            "F1-score на GridSearchCV для логистической регресии равен 0.79\n"
          ]
        }
      ],
      "source": [
        "#Сравним результат с BaseLine\n",
        "print('F1-score на Baseline для логистической регресии равен {:.2f}'.format(f1_logReg_base))\n",
        "print('F1-score на GridSearchCV для логистической регресии равен {:.2f}'.format(f1_gs_logReg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4aE5Y6K_1wL"
      },
      "source": [
        "*К сожалению метрику улучшить не удалось*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTS1nOvO_9ob"
      },
      "source": [
        "На основе Случайного Леса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuuGYdqJ_qDF",
        "outputId": "8c7e5a2b-5781-446d-cc19-8dce70d8c846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 17.6 s, sys: 1.34 s, total: 19 s\n",
            "Wall time: 17min 59s\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'n_estimators': list(range(80, 200, 30)),\n",
        "              'min_samples_leaf': list(np.linspace(5, 25, 10, dtype=int)),\n",
        "              'max_depth': list(np.linspace(1, 30, 6, dtype=int))\n",
        "              }\n",
        "            \n",
        "gs_rf = GridSearchCV(\n",
        "    estimator = ensemble.RandomForestClassifier(random_state= 42),\n",
        "    param_grid = param_grid,\n",
        "    cv = 5,\n",
        "    n_jobs = -1,\n",
        "    scoring = 'f1'\n",
        ")\n",
        "\n",
        "%time gs_rf.fit(X_train, y_train)\n",
        "\n",
        "f1_gs_rf = gs_rf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edzwav_LARg9",
        "outputId": "8f280eca-0958-4ccb-b8c6-a28d57ab54e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наилучшие значения гиперпараметров: {'max_depth': 30, 'min_samples_leaf': 5, 'n_estimators': 140}\n"
          ]
        }
      ],
      "source": [
        "print(\"Наилучшие значения гиперпараметров: {}\".format(gs_rf.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjqMX-a1srO8",
        "outputId": "7b3622d8-a6e6-449d-aabd-9ca26ad94a43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для случайного леса равен 0.83\n",
            "F1-score на GridResearchCV для случайного леса равен 0.84\n"
          ]
        }
      ],
      "source": [
        "print('F1-score на Baseline для случайного леса равен {:.2f}'.format(f1_rf_base))\n",
        "print('F1-score на GridResearchCV для случайного леса равен {:.2f}'.format(f1_gs_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF0yOsF18t2u"
      },
      "source": [
        "*Метрика немного улучшилась*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTQLKOPA80Gy"
      },
      "source": [
        "## **RandomizedSearchCV**\n",
        "\n",
        "Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4ktb2x0suWk",
        "outputId": "7f2bc74b-fe24-4162-c50a-a78e81ec12ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 10.8 s, sys: 1.33 s, total: 12.1 s\n",
            "Wall time: 19min 23s\n"
          ]
        }
      ],
      "source": [
        "param_distribution = [\n",
        "    {'penalty' : ['l2', 'none'], # тип регуляризации\n",
        "    'solver' : ['newton-cg', 'lbfgs', 'sag'], # алгоритм оптимизации\n",
        "    'C': list(np.linspace(0.01, 1, 10, dtype=float))}, # уровень силы регурялизации\n",
        "    \n",
        "    #поскольку разные алгоритмы поддерживают разные типы регуляризации мы создадим еще 1 набор параметров\n",
        "    {'penalty': ['l1', 'l2'] ,\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'C': list(np.linspace(0.01, 1, 10, dtype=float))}\n",
        "]\n",
        "\n",
        "rs_logReg = RandomizedSearchCV(\n",
        "    estimator= linear_model.LogisticRegression(random_state=42, max_iter=50),\n",
        "    param_distributions=param_distribution,\n",
        "    cv = 5,\n",
        "    n_iter = 50,\n",
        "    n_jobs = -1,\n",
        "    scoring = 'f1'\n",
        ")\n",
        "\n",
        "%time rs_logReg.fit(X_train, y_train)\n",
        "\n",
        "f1_rs_logReg = rs_logReg.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eDH21jB845z",
        "outputId": "d9e438bc-f5cf-40d0-a678-5360c57cd503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наилучшие значения гиперпараметров: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.34}\n"
          ]
        }
      ],
      "source": [
        "print(\"Наилучшие значения гиперпараметров: {}\".format(rs_logReg.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo2MWmhBAr3e",
        "outputId": "ee55a199-396e-4106-8e80-f2a7a23fb8ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для логистической регресии равен 0.79\n",
            "F1-score на RandomizedSrearchCV для логистической регресии равен 0.80\n"
          ]
        }
      ],
      "source": [
        "#Сравним результат с BaseLine\n",
        "print('F1-score на Baseline для логистической регресии равен {:.2f}'.format(f1_logReg_base))\n",
        "print('F1-score на RandomizedSrearchCV для логистической регресии равен {:.2f}'.format(f1_rs_logReg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBl3mBb6Avx8"
      },
      "source": [
        "Случайный лес"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g__0RRm_At5O",
        "outputId": "23439d09-224a-415f-a35a-fb67283be4fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 6.49 s, sys: 353 ms, total: 6.85 s\n",
            "Wall time: 4min 6s\n"
          ]
        }
      ],
      "source": [
        "param_distribution = {\n",
        "    'min_samples_leaf' : list(np.linspace(5, 25, 10, dtype=int)),\n",
        "    'max_depth' : list(np.linspace(1, 30, 6, dtype = int)),\n",
        "    'n_estimators' : list(range(80, 200, 30))\n",
        "}\n",
        "\n",
        "rs_rf = RandomizedSearchCV(\n",
        "    estimator=ensemble.RandomForestClassifier(random_state=42),\n",
        "    param_distributions=param_distribution,\n",
        "    cv = 5,\n",
        "    n_iter = 50,\n",
        "    n_jobs = -1,\n",
        "    scoring = 'f1'\n",
        ")\n",
        "\n",
        "%time rs_rf.fit(X_train, y_train)\n",
        "\n",
        "f1_rs_rf = rs_rf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RsiaxP5CpsU",
        "outputId": "5a460f28-9cdf-4e72-9665-bc5e8f28eb3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наилучшие значения гиперпараметров: {'n_estimators': 140, 'min_samples_leaf': 5, 'max_depth': 30}\n"
          ]
        }
      ],
      "source": [
        "print(\"Наилучшие значения гиперпараметров: {}\".format(rs_rf.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhuf3omSCqH-",
        "outputId": "57e350e2-c134-42d5-c2bb-ee663f688dd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для случайного леса равен 0.83\n",
            "F1-score на RandomizedSrearchCV для случайного леса равен 0.84\n"
          ]
        }
      ],
      "source": [
        "#Сравним результат с BaseLine\n",
        "print('F1-score на Baseline для случайного леса равен {:.2f}'.format(f1_rf_base))\n",
        "print('F1-score на RandomizedSrearchCV для случайного леса равен {:.2f}'.format(f1_rs_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rDbxusMCvaj"
      },
      "source": [
        "## **HyperOpt**\n",
        "\n",
        "Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9fk3uTpD7In",
        "outputId": "7e6ab0f7-e342-4bbe-e02a-1be83cd0cbce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
            "Wall time: 5.96 µs\n",
            "100%|██████████| 50/50 [21:55<00:00, 26.31s/it, best loss: -0.7918486627890561]\n",
            "Наилучшие значения гиперпараметров {'C': 0.028607707583252345, 'penalty': 0, 'solver': 1}\n"
          ]
        }
      ],
      "source": [
        "# зададим пространство поиска гиперпараметров - получится 3 набора\n",
        "# так как для каждого типа регуляции подходят только определённые алгоритмы оптимизации\n",
        "space = {'penalty': hp.choice(label='penalty', options=['l2', 'none']) , # тип регуляризации\n",
        "              'solver': hp.choice(label='solver', options=['lbfgs', 'sag', 'newton-cg']), # алгоритм оптимизации\n",
        "              'C': hp.uniform('C', 0.01, 1)\n",
        "              } # алгоритм оптимизации\n",
        "\n",
        "# зафиксируем random_state\n",
        "random_state = 42\n",
        "\n",
        "def hyperopt(space, cv=5, X=X, y=y, random_state=random_state):\n",
        "    \"\"\" Функция, обучающая модель LogisticRegression\n",
        "    по переданным гиперпараметрам\n",
        "\n",
        "    Args:\n",
        "        space (dict): набор гиперпараметров\n",
        "        cv (int, optional=5): Количество холдов кросс-валидации. Defaults to 5.\n",
        "        X (DataFrame): DataFrame с признаками. Defaults to X_train.\n",
        "        y (Series): Series с целевым признаком. Defaults to y_train.\n",
        "        random_state (int): Рандомное число для воспроизводимости результата. Defaults to random_state.\n",
        "\n",
        "    Returns:\n",
        "        score(float): метрика F1\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model = linear_model.LogisticRegression(\n",
        "        penalty = space['penalty'],\n",
        "        solver = space['solver'],\n",
        "        C = np.abs(float(space['C'])),\n",
        "        l1_ratio = float(space['l1_ratio']),\n",
        "        random_state = random_state,\n",
        "        max_iter = 50        \n",
        "    )        \n",
        "    except KeyError:\n",
        "          \n",
        "        model = linear_model.LogisticRegression(\n",
        "        penalty = space['penalty'],\n",
        "        solver = space['solver'],\n",
        "        C = np.abs(float(space['C'])),\n",
        "        random_state = random_state,\n",
        "        max_iter = 50\n",
        "           )\n",
        "        \n",
        "     \n",
        "    # применим  cross validation \n",
        "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
        "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
        "    return -score\n",
        "\n",
        "\n",
        "\n",
        "%time\n",
        "              \n",
        "trials = Trials() # используется для логирования результатов  \n",
        "\n",
        "best = fmin(hyperopt, # наша функция \n",
        "          space = space, # пространство гиперпараметров\n",
        "          algo = tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
        "          max_evals = 50, # максимальное количество итераций\n",
        "          trials = trials, # логирование результатов\n",
        "          rstate = np.random.RandomState(random_state)# фиксируем для повторяемости результата\n",
        "         )\n",
        "print(f'Наилучшие значения гиперпараметров {best}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g6_N9BTEeRA",
        "outputId": "039ca93d-7f57-4807-a330-028af907ff63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'C': 0.028607707583252345, 'penalty': 'l2', 'solver': 'sag'}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from hyperopt import space_eval\n",
        "hyperparams = space_eval(space, best)\n",
        "hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F3c7zZMI28y",
        "outputId": "09f37960-d0dd-439a-a4d9-9d72c2d0d95e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "# рассчитаем точность для тестовой выборки\n",
        "model = linear_model.LogisticRegression(\n",
        "    random_state = random_state, \n",
        "    penalty = hyperparams['penalty'],\n",
        "    solver = hyperparams['solver'],\n",
        "    C = hyperparams['C']\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_ho_lr = model.predict(X_test)\n",
        "\n",
        "f1_ho_lr = metrics.f1_score(y_test, y_pred_ho_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cBk8KW9I6iK",
        "outputId": "17fccb59-3f2f-48c0-8aa5-5d000a715127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для логистической регресии равен 0.79\n",
            "F1-score на HyperOpt для логистической регресии равен 0.80\n"
          ]
        }
      ],
      "source": [
        "#Сравним результат с BaseLine\n",
        "print('F1-score на Baseline для логистической регресии равен {:.2f}'.format(f1_logReg_base))\n",
        "print('F1-score на HyperOpt для логистической регресии равен {:.2f}'.format(f1_ho_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDWDJ7qQJAvn"
      },
      "source": [
        "Случайный лес"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RVcA2UNnI_Ar"
      },
      "outputs": [],
      "source": [
        "space={'n_estimators': hp.quniform('n_estimators', 80, 200, 1),\n",
        "       'max_depth' : hp.quniform('max_depth', 1, 30, 1),\n",
        "       'min_samples_leaf': hp.quniform('min_samples_leaf', 5, 25, 1)\n",
        "      }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "lTXKiivrJDLv"
      },
      "outputs": [],
      "source": [
        "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
        "    \n",
        "    params = {'n_estimators': int(params['n_estimators']), \n",
        "              'max_depth': int(params['max_depth']), \n",
        "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
        "    }\n",
        "    # используем эту комбинацию для построения модели   \n",
        "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
        "\n",
        "    # обучаем модель\n",
        "    model.fit(X, y)\n",
        "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
        "    \n",
        "    return -score    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz8iI_YbJE7Q",
        "outputId": "625b3eca-109c-4693-a677-66cad6e5ed0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 35 µs, sys: 0 ns, total: 35 µs\n",
            "Wall time: 56 µs\n",
            "100%|██████████| 50/50 [07:24<00:00,  8.88s/it, best loss: -0.8014811813337108]\n",
            "Наилучшие значения гиперпараметров {'max_depth': 26.0, 'min_samples_leaf': 5.0, 'n_estimators': 143.0}\n"
          ]
        }
      ],
      "source": [
        "%time\n",
        "\n",
        "trials = Trials() # используется для логирования результатов\n",
        "\n",
        "best = fmin(hyperopt_rf, # наша функция \n",
        "          space = space, # пространство гиперпараметров\n",
        "          algo = tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
        "          max_evals = 50, # максимальное количество итераций\n",
        "          trials = trials, # логирование результатов\n",
        "          rstate = np.random.RandomState(random_state)# фиксируем для повторяемости результата\n",
        "         )\n",
        "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "crs9_Er4JHQe"
      },
      "outputs": [],
      "source": [
        "# рассчитаем точность для тестовой выборки\n",
        "model = ensemble.RandomForestClassifier(\n",
        "    random_state = random_state, \n",
        "    n_estimators = int(best['n_estimators']),\n",
        "    max_depth = int(best['max_depth']),\n",
        "    min_samples_leaf = int(best['min_samples_leaf'])\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_ho_rf = model.predict(X_test)\n",
        "\n",
        "f1_ho_rf = metrics.f1_score(y_test, y_pred_ho_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2MnR32WK0nd",
        "outputId": "a9230ee1-0ad3-4157-8fa8-340cbb966000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для случайного леса равен 0.83\n",
            "F1-score на HyperOpt для случайного леса равен 0.83\n"
          ]
        }
      ],
      "source": [
        "#Сравним результат с BaseLine\n",
        "print('F1-score на Baseline для случайного леса равен {:.2f}'.format(f1_rf_base))\n",
        "print('F1-score на HyperOpt для случайного леса равен {:.2f}'.format(f1_ho_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0_r_K2hK4-9"
      },
      "source": [
        "## **Optuna**\n",
        "\n",
        "Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "jDemj9nTK255"
      },
      "outputs": [],
      "source": [
        "def optuna_lr(trial):\n",
        "    penalty = trial.suggest_categorical(name='penalty', choices= ['l2', 'none']) # тип регуляризации\n",
        "    solver = trial.suggest_categorical(name = 'solver', choices= ['newton-cg', 'lbfgs', 'sag']) # алгоритм оптимизации\n",
        "    C = trial.suggest_float(name='C', low=0.01, high=1, step = 0.1) # уровень силы регурялизации\n",
        "    \n",
        "    model = linear_model.LogisticRegression(\n",
        "        penalty = penalty,\n",
        "        solver = solver,\n",
        "        C = C,\n",
        "        random_state = random_state\n",
        "    )\n",
        "    \n",
        "    model.fit(X_train, y_train)\n",
        "    score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"f1\", n_jobs=-1).mean()\n",
        "    \n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2zwm5y3K8mA",
        "outputId": "3d1261a9-0690-4675-d7a1-3b388c9aaa5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-16 09:13:55,998]\u001b[0m A new study created in memory with name: LogisticRegression\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-11-16 09:14:02,597]\u001b[0m Trial 0 finished with value: 0.7552105607977898 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.11}. Best is trial 0 with value: 0.7552105607977898.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:18:26,066]\u001b[0m Trial 1 finished with value: 0.7213884309422244 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'C': 0.91}. Best is trial 0 with value: 0.7552105607977898.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:22:47,953]\u001b[0m Trial 2 finished with value: 0.7213884309422244 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'C': 0.01}. Best is trial 0 with value: 0.7552105607977898.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:23:14,983]\u001b[0m Trial 3 finished with value: 0.7799921548046879 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.31000000000000005}. Best is trial 3 with value: 0.7799921548046879.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:23:35,863]\u001b[0m Trial 4 finished with value: 0.7721107699415347 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.6100000000000001}. Best is trial 3 with value: 0.7799921548046879.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:23:51,602]\u001b[0m Trial 5 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-11-16 09:23:57,591]\u001b[0m Trial 6 finished with value: 0.7552105607977898 and parameters: {'penalty': 'none', 'solver': 'lbfgs', 'C': 0.51}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:28:16,544]\u001b[0m Trial 7 finished with value: 0.7213884309422244 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'C': 0.7100000000000001}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:28:44,563]\u001b[0m Trial 8 finished with value: 0.7696711455789366 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.91}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:33:45,886]\u001b[0m Trial 9 finished with value: 0.7213884309422244 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'C': 0.81}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-11-16 09:33:52,138]\u001b[0m Trial 10 finished with value: 0.779237413989353 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.31000000000000005}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:34:19,414]\u001b[0m Trial 11 finished with value: 0.7799921548046879 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.31000000000000005}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:34:48,391]\u001b[0m Trial 12 finished with value: 0.7805104493934761 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.21000000000000002}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:35:16,545]\u001b[0m Trial 13 finished with value: 0.7820005016970459 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.11}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:35:39,015]\u001b[0m Trial 14 finished with value: 0.7743180436015331 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.01}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:36:07,518]\u001b[0m Trial 15 finished with value: 0.7820005016970459 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.11}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:36:27,217]\u001b[0m Trial 16 finished with value: 0.7772292673632061 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.41000000000000003}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:36:54,174]\u001b[0m Trial 17 finished with value: 0.7820005016970459 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.11}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:37:11,953]\u001b[0m Trial 18 finished with value: 0.7803982420461868 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.21000000000000002}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-11-16 09:37:17,043]\u001b[0m Trial 19 finished with value: 0.7737257662151599 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.51}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:37:38,803]\u001b[0m Trial 20 finished with value: 0.7743180436015331 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.01}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:38:05,954]\u001b[0m Trial 21 finished with value: 0.7820005016970459 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.11}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:38:34,458]\u001b[0m Trial 22 finished with value: 0.7805104493934761 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.21000000000000002}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:39:01,405]\u001b[0m Trial 23 finished with value: 0.7820005016970459 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.11}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:39:30,319]\u001b[0m Trial 24 finished with value: 0.7778486011141373 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.41000000000000003}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:39:46,099]\u001b[0m Trial 25 finished with value: 0.7803982420461868 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.21000000000000002}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:40:07,819]\u001b[0m Trial 26 finished with value: 0.7743180436015331 and parameters: {'penalty': 'l2', 'solver': 'sag', 'C': 0.01}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:40:22,735]\u001b[0m Trial 27 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:40:39,164]\u001b[0m Trial 28 finished with value: 0.7794872072632637 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.31000000000000005}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:45:12,227]\u001b[0m Trial 29 finished with value: 0.7213884309422244 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'C': 0.21000000000000002}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:45:15,820]\u001b[0m Trial 30 finished with value: 0.7749459870866194 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.01}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:45:30,858]\u001b[0m Trial 31 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:45:44,267]\u001b[0m Trial 32 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:45:56,043]\u001b[0m Trial 33 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:50:03,165]\u001b[0m Trial 34 finished with value: 0.7213884309422244 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'C': 0.01}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:50:20,398]\u001b[0m Trial 35 finished with value: 0.7803982420461868 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.21000000000000002}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:50:35,518]\u001b[0m Trial 36 finished with value: 0.7794872072632637 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.31000000000000005}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:54:46,914]\u001b[0m Trial 37 finished with value: 0.7213884309422244 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'C': 0.01}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:55:01,692]\u001b[0m Trial 38 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 09:59:16,866]\u001b[0m Trial 39 finished with value: 0.7213884309422244 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'C': 0.41000000000000003}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:59:35,606]\u001b[0m Trial 40 finished with value: 0.7721107699415347 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.6100000000000001}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 09:59:50,102]\u001b[0m Trial 41 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 10:00:04,101]\u001b[0m Trial 42 finished with value: 0.7803982420461868 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.21000000000000002}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 10:00:17,717]\u001b[0m Trial 43 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 10:00:31,852]\u001b[0m Trial 44 finished with value: 0.7837290544819175 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.11}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 10:00:40,728]\u001b[0m Trial 45 finished with value: 0.7749459870866194 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.01}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\u001b[32m[I 2022-11-16 10:00:47,261]\u001b[0m Trial 46 finished with value: 0.7716759100571287 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.81}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\u001b[32m[I 2022-11-16 10:04:51,847]\u001b[0m Trial 47 finished with value: 0.7213884309422244 and parameters: {'penalty': 'none', 'solver': 'newton-cg', 'C': 0.31000000000000005}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 10:05:08,171]\u001b[0m Trial 48 finished with value: 0.7803982420461868 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.21000000000000002}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.01, 1] and step=0.1, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  low=low, old_high=old_high, high=high, step=step\n",
            "\u001b[32m[I 2022-11-16 10:05:16,095]\u001b[0m Trial 49 finished with value: 0.7749459870866194 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.01}. Best is trial 5 with value: 0.7837290544819175.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 25min 1s, sys: 1min 43s, total: 26min 45s\n",
            "Wall time: 51min 20s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "study = optuna.create_study(study_name='LogisticRegression', direction='maximize')\n",
        "\n",
        "study.optimize(optuna_lr, n_trials= 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "bnUcFgA1K-ht"
      },
      "outputs": [],
      "source": [
        "model = linear_model.LogisticRegression(**study.best_params, random_state=random_state)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_optuna_lr = model.predict(X_test)\n",
        "\n",
        "f1_optuna_lr = metrics.f1_score(y_test, y_pred_optuna_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydq3nNrrNu0Z",
        "outputId": "aaa6719e-020b-4156-e3d9-8b5828e134af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для логистической регресии равен 0.79\n",
            "F1-score на Optuna для логистической регресии равен 0.79\n"
          ]
        }
      ],
      "source": [
        "#Сравним результат с BaseLine\n",
        "print('F1-score на Baseline для логистической регресии равен {:.2f}'.format(f1_logReg_base))\n",
        "print('F1-score на Optuna для логистической регресии равен {:.2f}'.format(f1_optuna_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kYw6NQ0NyZC"
      },
      "source": [
        "Случайный лес"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "PtSS31XcNwoz"
      },
      "outputs": [],
      "source": [
        "def optuna_rf(trial):\n",
        "    n_estimators =  trial.suggest_int('n_estimators', 80, 200, 1)\n",
        "    max_depth = trial.suggest_int('max_depth', 1, 30, 1)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 5, 25, 1)\n",
        "    \n",
        "    model = ensemble.RandomForestClassifier(\n",
        "        n_estimators = n_estimators,\n",
        "        max_depth = max_depth,\n",
        "        min_samples_leaf = min_samples_leaf,\n",
        "        random_state = random_state \n",
        "    )\n",
        "    \n",
        "    model.fit(X_train, y_train)\n",
        "    score = cross_val_score(model, X_train, y_train, cv = 5, scoring = 'f1', n_jobs= -1).mean()\n",
        "    \n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eu7HpfsN0sU",
        "outputId": "f743a187-ad6c-493a-f49d-bd869e232005"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-16 10:05:19,887]\u001b[0m A new study created in memory with name: RandomForestClassification\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:05:25,988]\u001b[0m Trial 0 finished with value: 0.7715536235447596 and parameters: {'n_estimators': 115, 'max_depth': 26, 'min_samples_leaf': 21}. Best is trial 0 with value: 0.7715536235447596.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:05:28,173]\u001b[0m Trial 1 finished with value: 0.7265528869608301 and parameters: {'n_estimators': 96, 'max_depth': 2, 'min_samples_leaf': 19}. Best is trial 0 with value: 0.7715536235447596.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:05:35,325]\u001b[0m Trial 2 finished with value: 0.7726968938159083 and parameters: {'n_estimators': 157, 'max_depth': 18, 'min_samples_leaf': 23}. Best is trial 2 with value: 0.7726968938159083.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:05:39,828]\u001b[0m Trial 3 finished with value: 0.7763241768638831 and parameters: {'n_estimators': 88, 'max_depth': 17, 'min_samples_leaf': 18}. Best is trial 3 with value: 0.7763241768638831.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:05:47,398]\u001b[0m Trial 4 finished with value: 0.7814270048828271 and parameters: {'n_estimators': 155, 'max_depth': 17, 'min_samples_leaf': 17}. Best is trial 4 with value: 0.7814270048828271.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:05:51,864]\u001b[0m Trial 5 finished with value: 0.7852228773418288 and parameters: {'n_estimators': 84, 'max_depth': 21, 'min_samples_leaf': 13}. Best is trial 5 with value: 0.7852228773418288.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:05:58,820]\u001b[0m Trial 6 finished with value: 0.7810836919253239 and parameters: {'n_estimators': 148, 'max_depth': 19, 'min_samples_leaf': 18}. Best is trial 5 with value: 0.7852228773418288.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:06:05,568]\u001b[0m Trial 7 finished with value: 0.7838279923285222 and parameters: {'n_estimators': 123, 'max_depth': 23, 'min_samples_leaf': 14}. Best is trial 5 with value: 0.7852228773418288.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:06:11,340]\u001b[0m Trial 8 finished with value: 0.7749127058260044 and parameters: {'n_estimators': 113, 'max_depth': 13, 'min_samples_leaf': 23}. Best is trial 5 with value: 0.7852228773418288.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:06:19,714]\u001b[0m Trial 9 finished with value: 0.7672851538337373 and parameters: {'n_estimators': 191, 'max_depth': 7, 'min_samples_leaf': 13}. Best is trial 5 with value: 0.7852228773418288.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:06:32,447]\u001b[0m Trial 10 finished with value: 0.7991979147306016 and parameters: {'n_estimators': 198, 'max_depth': 30, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.7991979147306016.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:06:45,141]\u001b[0m Trial 11 finished with value: 0.7988139400619344 and parameters: {'n_estimators': 197, 'max_depth': 28, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.7991979147306016.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:06:56,791]\u001b[0m Trial 12 finished with value: 0.7985766075441063 and parameters: {'n_estimators': 190, 'max_depth': 30, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.7991979147306016.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:07:08,195]\u001b[0m Trial 13 finished with value: 0.7974356514053134 and parameters: {'n_estimators': 175, 'max_depth': 30, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.7991979147306016.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:07:19,960]\u001b[0m Trial 14 finished with value: 0.7951302158587147 and parameters: {'n_estimators': 199, 'max_depth': 26, 'min_samples_leaf': 9}. Best is trial 10 with value: 0.7991979147306016.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:07:29,813]\u001b[0m Trial 15 finished with value: 0.7877723263918918 and parameters: {'n_estimators': 173, 'max_depth': 12, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.7991979147306016.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:07:40,723]\u001b[0m Trial 16 finished with value: 0.8020111072311635 and parameters: {'n_estimators': 176, 'max_depth': 26, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8020111072311635.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:07:51,297]\u001b[0m Trial 17 finished with value: 0.7947413830985143 and parameters: {'n_estimators': 172, 'max_depth': 25, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.8020111072311635.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:08:03,166]\u001b[0m Trial 18 finished with value: 0.8026173358307769 and parameters: {'n_estimators': 180, 'max_depth': 22, 'min_samples_leaf': 5}. Best is trial 18 with value: 0.8026173358307769.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:08:12,441]\u001b[0m Trial 19 finished with value: 0.8020057640620643 and parameters: {'n_estimators': 135, 'max_depth': 22, 'min_samples_leaf': 5}. Best is trial 18 with value: 0.8026173358307769.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:08:22,060]\u001b[0m Trial 20 finished with value: 0.7873880644963205 and parameters: {'n_estimators': 182, 'max_depth': 14, 'min_samples_leaf': 11}. Best is trial 18 with value: 0.8026173358307769.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:08:32,862]\u001b[0m Trial 21 finished with value: 0.8024721136070327 and parameters: {'n_estimators': 133, 'max_depth': 22, 'min_samples_leaf': 5}. Best is trial 18 with value: 0.8026173358307769.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:08:44,165]\u001b[0m Trial 22 finished with value: 0.8002369386193993 and parameters: {'n_estimators': 162, 'max_depth': 24, 'min_samples_leaf': 5}. Best is trial 18 with value: 0.8026173358307769.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:08:52,462]\u001b[0m Trial 23 finished with value: 0.7981873770891458 and parameters: {'n_estimators': 137, 'max_depth': 20, 'min_samples_leaf': 8}. Best is trial 18 with value: 0.8026173358307769.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:09:02,730]\u001b[0m Trial 24 finished with value: 0.8031220331059327 and parameters: {'n_estimators': 147, 'max_depth': 22, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:09:09,981]\u001b[0m Trial 25 finished with value: 0.7812592079861543 and parameters: {'n_estimators': 129, 'max_depth': 11, 'min_samples_leaf': 11}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:09:19,158]\u001b[0m Trial 26 finished with value: 0.7955904652172145 and parameters: {'n_estimators': 145, 'max_depth': 21, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:09:24,338]\u001b[0m Trial 27 finished with value: 0.7735835911222456 and parameters: {'n_estimators': 107, 'max_depth': 15, 'min_samples_leaf': 25}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:09:34,548]\u001b[0m Trial 28 finished with value: 0.8024409753927652 and parameters: {'n_estimators': 163, 'max_depth': 24, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:09:44,975]\u001b[0m Trial 29 finished with value: 0.7673112711727853 and parameters: {'n_estimators': 122, 'max_depth': 9, 'min_samples_leaf': 16}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:09:54,893]\u001b[0m Trial 30 finished with value: 0.7859337624040714 and parameters: {'n_estimators': 144, 'max_depth': 27, 'min_samples_leaf': 11}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:10:06,039]\u001b[0m Trial 31 finished with value: 0.8012252672486806 and parameters: {'n_estimators': 166, 'max_depth': 23, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:10:16,165]\u001b[0m Trial 32 finished with value: 0.8011869605579628 and parameters: {'n_estimators': 153, 'max_depth': 24, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:10:27,352]\u001b[0m Trial 33 finished with value: 0.7987609279467821 and parameters: {'n_estimators': 166, 'max_depth': 19, 'min_samples_leaf': 6}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:10:32,065]\u001b[0m Trial 34 finished with value: 0.7243884774714836 and parameters: {'n_estimators': 160, 'max_depth': 2, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:10:43,350]\u001b[0m Trial 35 finished with value: 0.7760173348699432 and parameters: {'n_estimators': 151, 'max_depth': 16, 'min_samples_leaf': 20}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:10:53,885]\u001b[0m Trial 36 finished with value: 0.7913966036828504 and parameters: {'n_estimators': 181, 'max_depth': 28, 'min_samples_leaf': 9}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:11:01,390]\u001b[0m Trial 37 finished with value: 0.7959261717855551 and parameters: {'n_estimators': 100, 'max_depth': 18, 'min_samples_leaf': 6}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:11:09,590]\u001b[0m Trial 38 finished with value: 0.8015450468715436 and parameters: {'n_estimators': 125, 'max_depth': 22, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:11:17,714]\u001b[0m Trial 39 finished with value: 0.7976877301023733 and parameters: {'n_estimators': 131, 'max_depth': 21, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:11:26,322]\u001b[0m Trial 40 finished with value: 0.7850713641182505 and parameters: {'n_estimators': 144, 'max_depth': 17, 'min_samples_leaf': 13}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:11:40,315]\u001b[0m Trial 41 finished with value: 0.8028835776561293 and parameters: {'n_estimators': 183, 'max_depth': 26, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:11:53,652]\u001b[0m Trial 42 finished with value: 0.7984506306641999 and parameters: {'n_estimators': 186, 'max_depth': 24, 'min_samples_leaf': 6}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:12:04,014]\u001b[0m Trial 43 finished with value: 0.8005822651590808 and parameters: {'n_estimators': 157, 'max_depth': 28, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:12:16,454]\u001b[0m Trial 44 finished with value: 0.7998699883238574 and parameters: {'n_estimators': 167, 'max_depth': 19, 'min_samples_leaf': 5}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:12:27,997]\u001b[0m Trial 45 finished with value: 0.7974604137801115 and parameters: {'n_estimators': 181, 'max_depth': 23, 'min_samples_leaf': 8}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:12:40,998]\u001b[0m Trial 46 finished with value: 0.7986222533812016 and parameters: {'n_estimators': 192, 'max_depth': 25, 'min_samples_leaf': 6}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:12:49,017]\u001b[0m Trial 47 finished with value: 0.7820313869219587 and parameters: {'n_estimators': 150, 'max_depth': 21, 'min_samples_leaf': 15}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:12:57,356]\u001b[0m Trial 48 finished with value: 0.7889794544351711 and parameters: {'n_estimators': 140, 'max_depth': 27, 'min_samples_leaf': 10}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n",
            "\u001b[32m[I 2022-11-16 10:13:08,931]\u001b[0m Trial 49 finished with value: 0.8009418311045859 and parameters: {'n_estimators': 171, 'max_depth': 25, 'min_samples_leaf': 7}. Best is trial 24 with value: 0.8031220331059327.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 56s, sys: 2.24 s, total: 1min 58s\n",
            "Wall time: 7min 49s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "study = optuna.create_study(study_name='RandomForestClassification', direction='maximize')\n",
        "\n",
        "study.optimize(optuna_rf, n_trials= 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "mde-euWSN2Qt"
      },
      "outputs": [],
      "source": [
        "model = ensemble.RandomForestClassifier(**study.best_params, random_state=random_state)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_optuna_rf = model.predict(X_test)\n",
        "\n",
        "f1_optuna_rf = metrics.f1_score(y_test, y_pred_optuna_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0NagJvuPRou",
        "outputId": "e9a5faa1-66e5-48dd-dca0-0bc28e660a65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для Случайного леса равен 0.83\n",
            "F1-score на Optuna для Случайного леса равен 0.84\n"
          ]
        }
      ],
      "source": [
        "#Сравним результат с BaseLine\n",
        "print('F1-score на Baseline для Случайного леса равен {:.2f}'.format(f1_rf_base))\n",
        "print('F1-score на Optuna для Случайного леса равен {:.2f}'.format(f1_optuna_rf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "PLYIJOHI6oBT",
        "outputId": "8afd0fff-3e58-4d2c-e484-bdc286cce2fe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"80a0af53-763c-4124-8a4e-44378ce07c45\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"80a0af53-763c-4124-8a4e-44378ce07c45\")) {                    Plotly.newPlot(                        \"80a0af53-763c-4124-8a4e-44378ce07c45\",                        [{\"mode\":\"markers\",\"name\":\"F1-score\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.7715536235447596,0.7265528869608301,0.7726968938159083,0.7763241768638831,0.7814270048828271,0.7852228773418288,0.7810836919253239,0.7838279923285222,0.7749127058260044,0.7672851538337373,0.7991979147306016,0.7988139400619344,0.7985766075441063,0.7974356514053134,0.7951302158587147,0.7877723263918918,0.8020111072311635,0.7947413830985143,0.8026173358307769,0.8020057640620643,0.7873880644963205,0.8024721136070327,0.8002369386193993,0.7981873770891458,0.8031220331059327,0.7812592079861543,0.7955904652172145,0.7735835911222456,0.8024409753927652,0.7673112711727853,0.7859337624040714,0.8012252672486806,0.8011869605579628,0.7987609279467821,0.7243884774714836,0.7760173348699432,0.7913966036828504,0.7959261717855551,0.8015450468715436,0.7976877301023733,0.7850713641182505,0.8028835776561293,0.7984506306641999,0.8005822651590808,0.7998699883238574,0.7974604137801115,0.7986222533812016,0.7820313869219587,0.7889794544351711,0.8009418311045859],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.7715536235447596,0.7715536235447596,0.7726968938159083,0.7763241768638831,0.7814270048828271,0.7852228773418288,0.7852228773418288,0.7852228773418288,0.7852228773418288,0.7852228773418288,0.7991979147306016,0.7991979147306016,0.7991979147306016,0.7991979147306016,0.7991979147306016,0.7991979147306016,0.8020111072311635,0.8020111072311635,0.8026173358307769,0.8026173358307769,0.8026173358307769,0.8026173358307769,0.8026173358307769,0.8026173358307769,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327,0.8031220331059327],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"F1-score\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('80a0af53-763c-4124-8a4e-44378ce07c45');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optuna.visualization.plot_optimization_history(study, target_name=\"F1-score\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4KG_R0jPUhn"
      },
      "source": [
        "## **Итоги**\n",
        "\n",
        "Линейная регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XssPEUZTPTCb",
        "outputId": "8e95e138-9fd9-4330-9ac9-01736795620d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для логистической регресии равен 0.79\n",
            "F1-score на GridSearchCV для логистической регресии равен 0.79\n",
            "F1-score на RandomizedSrearchCV для логистической регресии равен 0.80\n",
            "F1-score на HyperOpt для логистической регресии равен 0.80\n",
            "F1-score на Optuna для логистической регресии равен 0.79\n"
          ]
        }
      ],
      "source": [
        "print('F1-score на Baseline для логистической регресии равен {:.2f}'.format(f1_logReg_base))\n",
        "print('F1-score на GridSearchCV для логистической регресии равен {:.2f}'.format(f1_gs_logReg))\n",
        "print('F1-score на RandomizedSrearchCV для логистической регресии равен {:.2f}'.format(f1_rs_logReg))\n",
        "print('F1-score на HyperOpt для логистической регресии равен {:.2f}'.format(f1_ho_lr))\n",
        "print('F1-score на Optuna для логистической регресии равен {:.2f}'.format(f1_optuna_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlzZf65ZPZEp"
      },
      "source": [
        "Случайный лес"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1Iq4ycaPW3j",
        "outputId": "fdd73495-2f58-4a32-f66b-8ce70ded03c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-score на Baseline для Случайного леса равен 0.83\n",
            "F1-score на GridResearchCV для случайного леса равен 0.84\n",
            "F1-score на RandomizedSrearchCV для случайного леса равен 0.84\n",
            "F1-score на HyperOpt для случайного леса равен 0.83\n",
            "F1-score на Optuna для Случайного леса равен 0.84\n"
          ]
        }
      ],
      "source": [
        "print('F1-score на Baseline для Случайного леса равен {:.2f}'.format(f1_rf_base))\n",
        "print('F1-score на GridResearchCV для случайного леса равен {:.2f}'.format(f1_gs_rf))\n",
        "print('F1-score на RandomizedSrearchCV для случайного леса равен {:.2f}'.format(f1_rs_rf))\n",
        "print('F1-score на HyperOpt для случайного леса равен {:.2f}'.format(f1_ho_rf))\n",
        "print('F1-score на Optuna для Случайного леса равен {:.2f}'.format(f1_optuna_rf))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "321ab55950f37df101268a46266f5dff6fbc802a7a8ebb790c29b4e197aadd34"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
