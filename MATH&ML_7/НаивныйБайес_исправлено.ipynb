{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlVC5j9gdd99"
   },
   "source": [
    "# Наивный байесовский классификатор для классификации спам-сообщений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "i35VBQfFdd-E"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем файл (разделителем здесь выступает символ табуляции)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A1b5QrS5dd-F",
    "outputId": "ad0e2dbf-f406-41ae-8cda-9e043efb2f8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/SMSSpamCollection.csv\", header=None, sep=\"\\t\", names=[\"Label\", \"SMS\"]\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, сколько объектов каждого класса присутствует в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "p7_2JzUvdd-G",
    "outputId": "6167fcf9-f386-48cf-b2fe-4ca8012835c1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что датасет несбалансированный – не-спама значительно больше, чем спама."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQG2a4SVdd-H"
   },
   "source": [
    "# Предобработка данных\n",
    "Удаляем символы, не являющиеся буквами, приводим тексты SMS к нижнему регистру, разбиваем строки на слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Jd-UcYg6dd-I"
   },
   "outputs": [],
   "source": [
    "df[\"SMS\"] = (\n",
    "    df[\"SMS\"].str.replace(r\"\\W+\", \" \", regex=True).str.lower().str.split()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_VfDYamMdd-K",
    "outputId": "0920421a-da46-433a-f724-f2ff0d094c2a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  [go, until, jurong, point, crazy, available, o...\n",
       "1   ham                     [ok, lar, joking, wif, u, oni]\n",
       "2  spam  [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
       "3   ham  [u, dun, say, so, early, hor, u, c, already, t...\n",
       "4   ham  [nah, i, don, t, think, he, goes, to, usf, he,..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50oksBrrdd-L"
   },
   "source": [
    "# Разделение на обучающую и тестовую выборки\n",
    "Разобьём датасет на обучающую и тестовую выборку в соотношении 80/20.Так как датасет несбалансированный, необходимо провести стратификацию – в обучающей и тестовой выборке должна быть примерно одна и та же доля спама."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Nies_07Ydd-L"
   },
   "outputs": [],
   "source": [
    "df_train = df.groupby(\"Label\", group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=0.8)\n",
    ")\n",
    "\n",
    "df_test = df.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WU_YwDxgdd-M",
    "outputId": "d7897ce6-95c9-4be3-f269-5009666c7f3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865859\n",
       "spam    0.134141\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fbrlnUxfdd-N",
    "outputId": "2bdc65d7-0b76-4c28-dae7-d1fe620e6a59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.866248\n",
       "spam    0.133752\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"Label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что и в обучающей, и в тестовой выборке содержится примерно 86.5% спама – как и в нашем оригинальном датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dHM1P3h2dd-N",
    "outputId": "4b2a0eba-0468-4e7d-e1dd-f091728cdecc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape=(4458, 2)\n",
      "df_test.shape=(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{df_train.shape=:}\")\n",
    "print(f\"{df_test.shape=:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CFWPJ6AOdd-N",
    "outputId": "21f76ebf-305c-43e5-8b54-ee656e601ff4",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, m, gonna, be, home, soon, and, i, don, t, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ahhh, work, i, vaguely, remember, that, what,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>[07732584351, rodger, burns, msg, we, tried, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[great, i, hope, you, like, your, man, well, e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  [nah, i, don, t, think, he, goes, to, usf, he,...\n",
       "1   ham  [i, m, gonna, be, home, soon, and, i, don, t, ...\n",
       "2   ham  [ahhh, work, i, vaguely, remember, that, what,...\n",
       "3  spam  [07732584351, rodger, burns, msg, we, tried, t...\n",
       "4   ham  [great, i, hope, you, like, your, man, well, e..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVmTrhNSdd-O"
   },
   "source": [
    "# Список слов\n",
    "Создаём список всех слов, встречающихся в обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ahLFpWI3dd-O"
   },
   "outputs": [],
   "source": [
    "vocabulary = list(set(df_train[\"SMS\"].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "eSN6U0QLdd-O",
    "outputId": "5dcb7d6f-900f-483c-e896-4ef69459dced"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doin',\n",
       " 'chatting',\n",
       " 'info',\n",
       " 'jelly',\n",
       " 'interfued',\n",
       " 'dammit',\n",
       " 'crazyin',\n",
       " 'cruise',\n",
       " 'wales']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[11:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MegzBwCFdd-P",
    "outputId": "fa6a956c-5602-4193-8925-6ecb43b5b719"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7792"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xs_mok2wdd-P"
   },
   "source": [
    "# Встречаемость слов\n",
    "Для каждого SMS-сообщения посчитаем, сколько раз в нём встречается каждое слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vER-xPhXdd-P"
   },
   "outputs": [],
   "source": [
    "words_counts = pd.DataFrame(\n",
    "    [\n",
    "        [text.count(word) for word in vocabulary]\n",
    "        for text in df_train[\"SMS\"].items()\n",
    "    ],\n",
    "    columns=vocabulary,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим частоты каждого слова в обучающий датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dNc8Juygdd-P"
   },
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, words_counts], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FxcXHWgqdd-Q",
    "outputId": "cda89d7c-4596-4dc7-e274-01afb214c54c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>tired</th>\n",
       "      <th>mouth</th>\n",
       "      <th>attach</th>\n",
       "      <th>motivate</th>\n",
       "      <th>ec2a</th>\n",
       "      <th>offered</th>\n",
       "      <th>plans</th>\n",
       "      <th>turkeys</th>\n",
       "      <th>...</th>\n",
       "      <th>golden</th>\n",
       "      <th>advance</th>\n",
       "      <th>aint</th>\n",
       "      <th>hockey</th>\n",
       "      <th>married</th>\n",
       "      <th>dude</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>organise</th>\n",
       "      <th>raj</th>\n",
       "      <th>extract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, m, leaving, my, house, now]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[from, tomorrow, onwards, eve, 6, to, 3, work]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[discussed, with, your, mother, ah]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, m, in, town, now, so, i, ll, jus, take, mr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, i, found, dis, pierre, cardin, one, which...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7794 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  tired  mouth  \\\n",
       "0   ham                    [i, m, leaving, my, house, now]      0      0   \n",
       "1   ham     [from, tomorrow, onwards, eve, 6, to, 3, work]      0      0   \n",
       "2   ham                [discussed, with, your, mother, ah]      0      0   \n",
       "3   ham  [i, m, in, town, now, so, i, ll, jus, take, mr...      0      0   \n",
       "4   ham  [ok, i, found, dis, pierre, cardin, one, which...      0      0   \n",
       "\n",
       "   attach  motivate  ec2a  offered  plans  turkeys  ...  golden  advance  \\\n",
       "0       0         0     0        0      0        0  ...       0        0   \n",
       "1       0         0     0        0      0        0  ...       0        0   \n",
       "2       0         0     0        0      0        0  ...       0        0   \n",
       "3       0         0     0        0      0        0  ...       0        0   \n",
       "4       0         0     0        0      0        0  ...       0        0   \n",
       "\n",
       "   aint  hockey  married  dude  bedroom  organise  raj  extract  \n",
       "0     0       0        0     0        0         0    0        0  \n",
       "1     0       0        0     0        0         0    0        0  \n",
       "2     0       0        0     0        0         0    0        0  \n",
       "3     0       0        0     0        0         0    0        0  \n",
       "4     0       0        0     0        0         0    0        0  \n",
       "\n",
       "[5 rows x 7794 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "On-SEF1fdd-Q"
   },
   "source": [
    "# Значения для формулы Байеса\n",
    "Посчитаем необходимые значения для формулы Байеса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "IwxBHjXYdd-Q"
   },
   "outputs": [],
   "source": [
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "gxsFfXOzdd-Q"
   },
   "outputs": [],
   "source": [
    "n_vocabulary = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ham, p_spam = df_train[\"Label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "D6I9Ho--dd-R"
   },
   "outputs": [],
   "source": [
    "n_spam = df_train[df_train[\"Label\"] == \"spam\"][\"SMS\"].apply(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2Xp_BhNhdd-R"
   },
   "outputs": [],
   "source": [
    "n_ham = df_train[df_train[\"Label\"] == \"ham\"][\"SMS\"].apply(len).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_vocabulary=7792\n",
      "p_spam=0.1341408703454464\n",
      "p_ham=0.8658591296545536\n",
      "n_spam=15198\n",
      "n_ham=57058\n"
     ]
    }
   ],
   "source": [
    "print(f\"{n_vocabulary=:}\")\n",
    "print(f\"{p_spam=:}\")\n",
    "print(f\"{p_ham=:}\")\n",
    "print(f\"{n_spam=:}\")\n",
    "print(f\"{n_ham=:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формула Байеса\n",
    "Напишем функцию для формулы Байеса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "jde0BGdPdd-R"
   },
   "outputs": [],
   "source": [
    "def p_word_spam(word: str) -> float:\n",
    "    \"\"\"\n",
    "    По формуле Байеса считает вероятность того, что слово является спамом.\n",
    "\n",
    "    Args:\n",
    "        word: слово\n",
    "\n",
    "    Returns:\n",
    "        Вероятность того, что слово – спам (1, если слова нет в df_train).\n",
    "    \"\"\"\n",
    "    return (\n",
    "        (df_train[df_train[\"Label\"] == \"spam\"][word].sum() + alpha)\n",
    "        / (n_spam + alpha * n_vocabulary)\n",
    "        if word in vocabulary\n",
    "        else 1.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-nPavNOdd-S"
   },
   "source": [
    "# Алгоритм классификации\n",
    "Напишем функцию для классификации сообщения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Ib39OrM8dd-S"
   },
   "outputs": [],
   "source": [
    "def classify(message) -> str:\n",
    "    \"\"\"\n",
    "    Классифицирует сообщение как спам или не спам.\n",
    "\n",
    "    Args:\n",
    "        message: сообщение (список слов)\n",
    "\n",
    "    Returns:\n",
    "        \"spam\" или \"ham\"\n",
    "    \"\"\"\n",
    "    p_spam_message = p_spam * np.prod(\n",
    "        [p_word_spam(word) for word in message]\n",
    "    )\n",
    "\n",
    "    p_ham_message = p_ham * np.prod(\n",
    "        [1 - p_word_spam(word) for word in message]\n",
    "    )\n",
    "\n",
    "    return \"spam\" if p_spam_message < p_ham_message else \"ham\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QECGrw8dd-S"
   },
   "source": [
    "# Предсказания\n",
    "Сделаем предсказания на тестовых данных. Это может занять несколько минут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Prediction\"] = [\n",
    "    classify(message) for message in df_test[\"SMS\"].tolist()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "AejY85XOdd-S",
    "outputId": "112fe436-4d36-42a6-8d3d-8952e282939c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, m, gonna, be, home, soon, and, i, don, t, ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ahhh, work, i, vaguely, remember, that, what,...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>[07732584351, rodger, burns, msg, we, tried, t...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[great, i, hope, you, like, your, man, well, e...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS Prediction\n",
       "0   ham  [nah, i, don, t, think, he, goes, to, usf, he,...       spam\n",
       "1   ham  [i, m, gonna, be, home, soon, and, i, don, t, ...        ham\n",
       "2   ham  [ahhh, work, i, vaguely, remember, that, what,...        ham\n",
       "3  spam  [07732584351, rodger, burns, msg, we, tried, t...        ham\n",
       "4   ham  [great, i, hope, you, like, your, man, well, e...        ham"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какой процент сообщений в тестовой выборке наш алгоритм классифицировал правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "lNHidizgdd-T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильных предсказаний 40.484740 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = (df_test[\"Prediction\"] == df_test[\"Label\"]).sum() / len(df_test)\n",
    "print(f\"Правильных предсказаний {accuracy * 100:3f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на сообщения, которые наш алгоритм классифицировал неправильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "-s5NRlJGdd-T",
    "outputId": "de7985cf-9878-486c-ff7a-54295961199e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>[07732584351, rodger, burns, msg, we, tried, t...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>[tell, where, you, reached]</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>[k, did, you, call, me, just, now, ah]</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, m, really, not, up, to, it, still, tonight...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS Prediction\n",
       "0   ham  [nah, i, don, t, think, he, goes, to, usf, he,...       spam\n",
       "3  spam  [07732584351, rodger, burns, msg, we, tried, t...        ham\n",
       "6   ham                        [tell, where, you, reached]       spam\n",
       "8   ham             [k, did, you, call, me, just, now, ah]       spam\n",
       "9   ham  [i, m, really, not, up, to, it, still, tonight...       spam"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test[\"Prediction\"] != df_test[\"Label\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3xAvBRndd-T"
   },
   "source": [
    "# Наивный байесовский классификатор в sklearn\n",
    "Ура, мы реализовали наивный байесовский классификатор с нуля!\n",
    "А теперь посмотрим, как то же самое можно сделать с помощью библиотеки scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем заново csv-файл и предобработаем данные. Разбивать сообщения на слова в этот раз не нужно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/SMSSpamCollection.csv\", header=None, sep=\"\\t\", names=[\"Label\", \"SMS\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SMS\"] = df[\"SMS\"].str.replace(r\"\\W+\", \" \", regex=True).str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем строки в векторный вид – то есть, снова создадим таблицу с частотами слов. Но в этот раз уже не вручную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df[\"SMS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим целевую переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью функции `train_test_split` из scikit-learn разобьём выборку на обучающую и тестовую в пропорции 80/20. Не забудем сделать стратификацию!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем наивный байесовский классификатор. Параметр `alpha` у него по умолчанию равен 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ComplementNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ComplementNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ComplementNB</label><div class=\"sk-toggleable__content\"><pre>ComplementNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9730941704035875\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, классификатор из sklearn работает намного лучше."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "НаивныйБайес.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "321ab55950f37df101268a46266f5dff6fbc802a7a8ebb790c29b4e197aadd34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
